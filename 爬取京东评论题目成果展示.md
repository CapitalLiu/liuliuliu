# 爬取京东评论题目成果展示

## 学习爬虫的详细过程放在另一个名为“爬虫学习” MD文件中
## 爬取的源代码在一个 名为“爬取京东2.py”的文件中
## 爬取的结果放在一个 名为“JINGDONG.txt”的文本中

完成这道题过程中学习的内容：
* 系统的学习python的基础知识
* 安装并配置anaconda环境
* 安装Pycharm并学习使用
* 学习requests库
* 学习BeautifulSoup库
* 学习re库及正则表达式
* 学习部分网络前端知识（HTML，XML，robot协议，JSON，YAML等）
* 学习Scrapy 框架
* 使用format格式化漂亮的输出
**该文件仅展示部分最后的结果**

这是源代码部分：

```python
import json
import requests
import re


def get_html(url):
    head = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'}
    try:
        r = requests.get(url, headers=head)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        print("这条评论爬取失败")


def trans_html(ulist, html):
    jd = json.loads(html.lstrip('fetchJSON_comment98(').rstrip(');'))
    datas = jd['comments']
    for data in datas:
        ID = data['id']
        content = data['content']
        time = data['creationTime']
        ulist.append([ID, content, time])


def print_html(ulist):
    count = 0
    for u in ulist:
        count += 1
        print("序号：{0:<4}用户名：{1:<15}\n".format(count, u[0]))
        print("评论：{:<}\n".format(u[1]))
        print("时间：{:<}\n".format(u[2]))


def main():
    ulist = []
    for i in range(0, 50 + 1):
        url = 'https://club.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98&productId=100019125569&score=0&sortType=5&page=' + str(i) + '&pageSize=10&isShadowSku=0&rid=0&fold=1'
        html = get_html(url)
        trans_html(ulist, html)
        print_html(ulist)

main()
```

爬取结果：

![](C:\Users\Lenovo-1\Pictures\Saved Pictures\爬取京东2.png)

![](C:\Users\Lenovo-1\Pictures\Saved Pictures\爬取京东2.2.png)

![](C:\Users\Lenovo-1\Pictures\Saved Pictures\爬取京东2.1.png)

![](C:\Users\Lenovo-1\Pictures\Saved Pictures\爬取京东2.3.png)

**总共爬取了510条评论内容，并且列出了用户名，评论内容以及评论的时间**

## 部分过程展示：



这是题目所要求爬取的网页：

![](C:\Users\Lenovo-1\Pictures\Saved Pictures\京东网页.png)

这是 找到评论的json格式源代码：
![](C:\Users\Lenovo-1\Pictures\Saved Pictures\爬取评论1.png)
